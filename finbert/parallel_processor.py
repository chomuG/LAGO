"""
ë³‘ë ¬ ì²˜ë¦¬ ë‰´ìŠ¤ í”„ë¡œì„¸ì„œ
ìµœëŒ€ 3-5ë°° ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ë³‘ë ¬ ì²˜ë¦¬ êµ¬í˜„
"""
import concurrent.futures
import threading
import time
import logging
from typing import List, Dict, Optional, Callable
from dataclasses import dataclass
from queue import Queue, Empty
import multiprocessing

logger = logging.getLogger(__name__)

@dataclass
class ProcessingTask:
    """ì²˜ë¦¬ ì‘ì—… ë‹¨ìœ„"""
    task_id: int
    task_type: str  # 'url_redirect', 'content_extract', 'sentiment', 'summary'
    data: Dict
    retry_count: int = 0
    max_retries: int = 2


class ParallelNewsProcessor:
    """ë³‘ë ¬ ë‰´ìŠ¤ ì²˜ë¦¬ ì—”ì§„"""
    
    def __init__(self, max_workers: int = None):
        """
        ë³‘ë ¬ ì²˜ë¦¬ ì´ˆê¸°í™”
        max_workers: ìµœëŒ€ ì›Œì»¤ ìˆ˜ (Noneì´ë©´ CPU ì½”ì–´ ìˆ˜ ê¸°ë°˜ ìë™ ì„¤ì •)
        """
        self.max_workers = max_workers or min(multiprocessing.cpu_count(), 4)
        self.executor = concurrent.futures.ThreadPoolExecutor(max_workers=self.max_workers)
        self.processing_stats = {
            'total': 0,
            'success': 0,
            'failed': 0,
            'cached': 0,
            'processing_time': 0
        }
        logger.info(f"ë³‘ë ¬ ì²˜ë¦¬ ì—”ì§„ ì´ˆê¸°í™” - ì›Œì»¤ ìˆ˜: {self.max_workers}")
    
    def process_news_batch(self, news_items: List, 
                          url_processor: Callable,
                          content_processor: Callable,
                          sentiment_processor: Callable,
                          summary_processor: Callable) -> List[Optional[Dict]]:
        """
        ë‰´ìŠ¤ ë°°ì¹˜ ë³‘ë ¬ ì²˜ë¦¬
        """
        start_time = time.time()
        total_items = len(news_items)
        logger.info(f"ğŸ“Š ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ - {total_items}ê°œ ë‰´ìŠ¤, {self.max_workers}ê°œ ì›Œì»¤")
        
        # ê²°ê³¼ ì €ì¥ìš© ë”•ì…”ë„ˆë¦¬
        results = {}
        futures_map = {}
        
        # Phase 1: URL ë¦¬ë””ë ‰ì…˜ ë³‘ë ¬ ì²˜ë¦¬
        logger.info("ğŸ”„ Phase 1: URL ë¦¬ë””ë ‰ì…˜ ë³‘ë ¬ ì²˜ë¦¬")
        url_futures = []
        for idx, news_item in enumerate(news_items):
            future = self.executor.submit(
                self._process_with_retry,
                url_processor,
                news_item.url,
                idx + 1,
                total_items
            )
            url_futures.append((idx, future))
            futures_map[future] = ('url', idx)
        
        # URL ì²˜ë¦¬ ê²°ê³¼ ìˆ˜ì§‘
        url_results = {}
        for idx, future in url_futures:
            try:
                result = future.result(timeout=15)
                if result:
                    url_results[idx] = result
                    logger.debug(f"âœ… URL [{idx+1}/{total_items}] ì²˜ë¦¬ ì™„ë£Œ")
                else:
                    logger.warning(f"âŒ URL [{idx+1}/{total_items}] ì²˜ë¦¬ ì‹¤íŒ¨")
            except Exception as e:
                logger.error(f"âŒ URL [{idx+1}/{total_items}] ì˜ˆì™¸: {e}")
        
        # Phase 2: ì½˜í…ì¸  ì¶”ì¶œ ë³‘ë ¬ ì²˜ë¦¬ (ì„±ê³µí•œ URLë§Œ)
        logger.info("ğŸ“„ Phase 2: ì½˜í…ì¸  ì¶”ì¶œ ë³‘ë ¬ ì²˜ë¦¬")
        content_futures = []
        for idx, final_url in url_results.items():
            future = self.executor.submit(
                self._process_with_retry,
                content_processor,
                final_url,
                idx + 1,
                total_items
            )
            content_futures.append((idx, future))
            futures_map[future] = ('content', idx)
        
        # ì½˜í…ì¸  ì²˜ë¦¬ ê²°ê³¼ ìˆ˜ì§‘
        content_results = {}
        for idx, future in content_futures:
            try:
                result = future.result(timeout=30)
                if result:
                    content_results[idx] = result
                    logger.debug(f"âœ… ì½˜í…ì¸  [{idx+1}/{total_items}] ì¶”ì¶œ ì™„ë£Œ")
                else:
                    logger.warning(f"âŒ ì½˜í…ì¸  [{idx+1}/{total_items}] ì¶”ì¶œ ì‹¤íŒ¨")
            except Exception as e:
                logger.error(f"âŒ ì½˜í…ì¸  [{idx+1}/{total_items}] ì˜ˆì™¸: {e}")
        
        # Phase 3: ê°ì„±ë¶„ì„ & ìš”ì•½ ë™ì‹œ ë³‘ë ¬ ì²˜ë¦¬
        logger.info("ğŸ§  Phase 3: ê°ì„±ë¶„ì„ & ìš”ì•½ ë™ì‹œ ë³‘ë ¬ ì²˜ë¦¬")
        
        analysis_futures = []
        for idx, content_data in content_results.items():
            # ê°ì„±ë¶„ì„ ì‘ì—…
            analysis_text = content_data.get('content_text') or content_data.get('summary_text')
            if analysis_text:
                sentiment_future = self.executor.submit(
                    sentiment_processor,
                    analysis_text,
                    idx + 1,
                    total_items
                )
                analysis_futures.append((idx, 'sentiment', sentiment_future))
            
            # ìš”ì•½ ì‘ì—… (Claude APIëŠ” Rate Limit ìˆìœ¼ë¯€ë¡œ ìˆœì°¨ì ìœ¼ë¡œ)
            # ì—¬ê¸°ì„œëŠ” ë³‘ë ¬ ì²˜ë¦¬í•˜ì§€ ì•Šê³  ë‚˜ì¤‘ì— ìˆœì°¨ ì²˜ë¦¬
        
        # ê°ì„±ë¶„ì„ ê²°ê³¼ ìˆ˜ì§‘
        sentiment_results = {}
        for idx, task_type, future in analysis_futures:
            if task_type == 'sentiment':
                try:
                    result = future.result(timeout=10)
                    sentiment_results[idx] = result
                    logger.debug(f"âœ… ê°ì„±ë¶„ì„ [{idx+1}/{total_items}] ì™„ë£Œ")
                except Exception as e:
                    logger.error(f"âŒ ê°ì„±ë¶„ì„ [{idx+1}/{total_items}] ì˜ˆì™¸: {e}")
                    sentiment_results[idx] = self._get_default_sentiment()
        
        # Phase 4: Claude ìš”ì•½ì€ Rate Limit ë•Œë¬¸ì— ìˆœì°¨ ì²˜ë¦¬ (í•˜ì§€ë§Œ ìºì‹±ìœ¼ë¡œ ë¹ ë¥´ê²Œ)
        logger.info("ğŸ“ Phase 4: Claude ìš”ì•½ ìˆœì°¨ ì²˜ë¦¬ (ìºì‹± í™œìš©)")
        summary_results = {}
        for idx, content_data in content_results.items():
            try:
                summary = summary_processor(
                    content_data.get('title', ''),
                    content_data.get('content_text', ''),
                    idx + 1,
                    total_items
                )
                summary_results[idx] = summary
                logger.debug(f"âœ… ìš”ì•½ [{idx+1}/{total_items}] ì™„ë£Œ")
            except Exception as e:
                logger.error(f"âŒ ìš”ì•½ [{idx+1}/{total_items}] ì˜ˆì™¸: {e}")
                summary_results[idx] = []
        
        # ìµœì¢… ê²°ê³¼ ì¡°í•©
        final_results = []
        for idx, news_item in enumerate(news_items):
            if idx not in content_results:
                final_results.append(None)
                continue
            
            result = {
                'title': content_results[idx].get('title'),
                'url': url_results.get(idx),
                'original_url': news_item.url,
                'source': news_item.source,
                'published_at': news_item.published_at.isoformat(),
                'category': news_item.category,
                'symbol': news_item.symbol,
                'collection_type': 'REALTIME',
                
                'content_text': content_results[idx].get('content_text', '')[:5000],
                'summary_text': content_results[idx].get('summary_text'),
                'summary_lines': summary_results.get(idx, []),
                
                'images': content_results[idx].get('images', [])[:10],
                'main_image_url': content_results[idx].get('main_image'),
                'total_images': len(content_results[idx].get('images', [])),
                
                'content_blocks': content_results[idx].get('blocks', [])[:20],
                
                **sentiment_results.get(idx, self._get_default_sentiment()),
                
                'parser_info': {
                    'parser_used': content_results[idx].get('parser_used'),
                    'confidence': content_results[idx].get('confidence'),
                    'processing_time': round(time.time() - start_time, 2)
                },
                'processing_status': 'success'
            }
            final_results.append(result)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        processing_time = time.time() - start_time
        self.processing_stats['total'] += total_items
        self.processing_stats['success'] += len([r for r in final_results if r])
        self.processing_stats['failed'] += len([r for r in final_results if not r])
        self.processing_stats['processing_time'] += processing_time
        
        logger.info(f"""
        ğŸ¯ ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ í†µê³„:
        - ì „ì²´: {total_items}ê°œ
        - ì„±ê³µ: {len([r for r in final_results if r])}ê°œ
        - ì‹¤íŒ¨: {len([r for r in final_results if not r])}ê°œ
        - ì²˜ë¦¬ ì‹œê°„: {processing_time:.2f}ì´ˆ
        - í‰ê·  ì²˜ë¦¬ ì‹œê°„: {processing_time/total_items:.2f}ì´ˆ/ê°œ
        - ì„±ëŠ¥ í–¥ìƒ: {total_items * 60 / processing_time:.1f}x (ìˆœì°¨ ëŒ€ë¹„ ì¶”ì •)
        """)
        
        return final_results
    
    def _process_with_retry(self, func: Callable, *args, **kwargs):
        """ì¬ì‹œë„ ë¡œì§ì´ í¬í•¨ëœ ì²˜ë¦¬"""
        max_retries = 2
        for attempt in range(max_retries):
            try:
                return func(*args, **kwargs)
            except Exception as e:
                if attempt < max_retries - 1:
                    logger.warning(f"ì²˜ë¦¬ ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_retries}): {e}")
                    time.sleep(1)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°
                else:
                    logger.error(f"ìµœì¢… ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                    raise
        return None
    
    def _get_default_sentiment(self) -> Dict:
        """ê¸°ë³¸ ê°ì„±ë¶„ì„ ê²°ê³¼"""
        return {
            'label': 'NEUTRAL',
            'score': 0.0,
            'confidence': 0.0,
            'confidence_level': 'LOW',
            'trading_signal': 'HOLD',
            'signal_strength': 'WEAK',
            'error': 'Processing failed'
        }
    
    def get_stats(self) -> Dict:
        """ì²˜ë¦¬ í†µê³„ ë°˜í™˜"""
        if self.processing_stats['total'] > 0:
            avg_time = self.processing_stats['processing_time'] / self.processing_stats['total']
        else:
            avg_time = 0
        
        return {
            **self.processing_stats,
            'avg_processing_time': round(avg_time, 2),
            'max_workers': self.max_workers
        }
    
    def shutdown(self):
        """ë³‘ë ¬ ì²˜ë¦¬ ì—”ì§„ ì¢…ë£Œ"""
        self.executor.shutdown(wait=True)
        logger.info("ë³‘ë ¬ ì²˜ë¦¬ ì—”ì§„ ì¢…ë£Œ ì™„ë£Œ")