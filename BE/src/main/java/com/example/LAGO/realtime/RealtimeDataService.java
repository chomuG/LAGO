package com.example.LAGO.realtime;

import com.example.LAGO.realtime.dto.TickData;
import com.fasterxml.jackson.databind.ObjectMapper;
import lombok.extern.slf4j.Slf4j;
import org.springframework.beans.factory.annotation.Qualifier;
import org.springframework.data.redis.core.RedisTemplate;
import org.springframework.messaging.simp.SimpMessagingTemplate;
import org.springframework.scheduling.annotation.Scheduled;
import org.springframework.stereotype.Service;

import java.time.Duration;
import java.time.LocalDateTime;
import java.time.ZoneId;
import java.util.*;
import java.util.concurrent.ConcurrentHashMap;

/**
 * KIS WebSocketìœ¼ë¡œë¶€í„° ë°›ì€ ì‹¤ì‹œê°„ í‹± ë°ì´í„°ë¥¼ ì••ì¶• ë°°ì¹˜ ì €ì¥í•˜ê³  ê´€ë¦¬í•˜ëŠ” ì„œë¹„ìŠ¤
 * í•˜ì´ë¸Œë¦¬ë“œ ë°©ì‹: ì••ì¶• ë°°ì¹˜ ì €ì¥(íˆìŠ¤í† ë¦¬) + ì‹¤ì‹œê°„ ì¡°íšŒ(ìµœì‹  ë°ì´í„°)
 */
@Slf4j
@Service
public class RealtimeDataService {
    
    private final RedisTemplate<String, String> redisTemplate;
    private final RedisTemplate<String, byte[]> binaryRedisTemplate;
    private final ObjectMapper objectMapper;
    private final StockIdMapper stockIdMapper;
    private static final ZoneId KST = ZoneId.of("Asia/Seoul"); // [NEW]
    private final RealTimeDataBroadcaster broadcaster;

    // (ì„ íƒ) ì¸ë±ìŠ¤ í‚¤ ìƒìˆ˜
    private static final String CHUNK_BLOB_KEY  = "ticks:chunk:%s:blob"; // [NEW]
    private static final String CHUNK_META_KEY  = "ticks:chunk:%s:meta"; // [NEW]
    private static final String CHUNKS_ZSET_ALL = "ticks:chunks";        // [NEW]
    private static final String CHUNKS_ZSET_BY_STOCK = "ticks:chunks:byStock:%d"; // [NEW]

    // ìƒì„±ì: ì´ í•˜ë‚˜ë§Œ ë‚¨ê¸°ì„¸ìš”
    public RealtimeDataService(
            RedisTemplate<String, String> redisTemplate,
            @Qualifier("binaryRedisTemplate") RedisTemplate<String, byte[]> binaryRedisTemplate,
            ObjectMapper objectMapper,
            StockIdMapper stockIdMapper,
            RealTimeDataBroadcaster broadcaster // ì¶”ê°€
    ) {
        this.redisTemplate = redisTemplate;
        this.binaryRedisTemplate = binaryRedisTemplate;
        this.objectMapper = objectMapper;
        this.stockIdMapper = stockIdMapper;
        this.broadcaster = broadcaster; // ì¶”ê°€
    }

    
    // ì••ì¶• ë°°ì¹˜ ì €ì¥ ì„¤ì •
    private static final int CHUNK_SIZE = 1000;
    private static final int ZSTD_LEVEL = 3;
    
    // ì¢…ëª©ë³„ ì²­í¬ ê´€ë¦¬ (ë©”ëª¨ë¦¬ ìºì‹œ)
    private final Map<Integer, TickChunk> stockChunks = new ConcurrentHashMap<>();
    
    // Redis Key íŒ¨í„´
    private static final String REALTIME_KEY_PREFIX = "realtime:stock:";  // ì‹¤ì‹œê°„ ì¡°íšŒìš©
    private static final String BATCH_KEY_PREFIX = "tick_batch:";        // ì••ì¶• ë°°ì¹˜ìš©
    private static final String META_KEY_PREFIX = "tick_meta:";          // ë©”íƒ€ë°ì´í„°ìš©
    private static final String LATEST_UPDATE_KEY = "realtime:latest_update";
    
    /**
     * KIS WebSocketì—ì„œ ë°›ì€ í‹± ë°ì´í„°ë¥¼ ì••ì¶• ë°°ì¹˜ ì €ì¥ + ì‹¤ì‹œê°„ ì¡°íšŒìš© ì €ì¥
     * 
     * @param tickData KIS í‹± ë°ì´í„°
     */
    public void saveTickData(TickData tickData) {
        try {
            if (!tickData.isValid()) {
                log.warn("Invalid tick data, skipping save: {}", tickData);
                return;
            }
            
            // 1. ì••ì¶• ë°°ì¹˜ ì €ì¥ ì²˜ë¦¬
            saveToCompressedBatch(tickData);
            
            // 2. ì‹¤ì‹œê°„ ì¡°íšŒìš© ìµœì‹  ë°ì´í„° ì €ì¥ (ê¸°ì¡´ ë°©ì‹ ìœ ì§€)
            saveLatestForQuery(tickData);

            // ì—¬ê¸°ì„œ ì‹¤ì‹œê°„ ì „ì†¡
            broadcaster.sendRealTimeData(tickData);
            
            log.debug("Processed tick data: {} - {}", tickData.getCode(), tickData.getClosePrice());
            
        } catch (Exception e) {
            log.error("Failed to save tick data: {}", e.getMessage(), e);
        }
    }
    
    /**
     * ì••ì¶• ë°°ì¹˜ ì €ì¥ ì²˜ë¦¬
     * @param tickData í‹± ë°ì´í„°
     */
    private void saveToCompressedBatch(TickData tickData) {
        // ì¢…ëª©ì½”ë“œë¥¼ IDë¡œ ë³€í™˜
        Integer stockId = stockIdMapper.getStockId(tickData.getCode());
        if (stockId == null) {
            log.warn("Unknown stock code, skipping batch save: {}", tickData.getCode());
            return;
        }
        
        // ì¢…ëª©ë³„ ì²­í¬ ê°€ì ¸ì˜¤ê¸° (ì—†ìœ¼ë©´ ìƒì„±)
        TickChunk chunk = stockChunks.computeIfAbsent(stockId, 
            k -> new TickChunk(CHUNK_SIZE));
        
        // ì²­í¬ì— ë°ì´í„° ì¶”ê°€
        if (!chunk.add16B(tickData, stockId)) {
            // ì²­í¬ê°€ ê°€ë“ ì°¸ â†’ Redisì— ì €ì¥í•˜ê³  ìƒˆ ì²­í¬ ìƒì„±
            saveBatchToRedis(stockId, chunk);
            
            // ìƒˆ ì²­í¬ ìƒì„± í›„ ë°ì´í„° ì¶”ê°€
            chunk = new TickChunk(CHUNK_SIZE);
            chunk.add16B(tickData, stockId);
            stockChunks.put(stockId, chunk);
        }
    }
    
    /**
     * ì‹¤ì‹œê°„ ì¡°íšŒìš© ìµœì‹  ë°ì´í„° ì €ì¥ (ê¸°ì¡´ ë°©ì‹)
     * @param tickData í‹± ë°ì´í„°
     */
    private void saveLatestForQuery(TickData tickData) {
        String key = REALTIME_KEY_PREFIX + tickData.getCode();
        
        // ë°ì´í„°ë¥¼ Hash í˜•íƒœë¡œ ì €ì¥
        Map<String, String> dataMap = new HashMap<>();
        dataMap.put("code", tickData.getCode());
        dataMap.put("date", tickData.getDate());
        dataMap.put("closePrice", tickData.getClosePrice().toString());
        dataMap.put("openPrice", tickData.getOpenPrice().toString());
        dataMap.put("highPrice", tickData.getHighPrice().toString());
        dataMap.put("lowPrice", tickData.getLowPrice().toString());
        dataMap.put("volume", tickData.getVolume().toString());
        dataMap.put("receivedAt", tickData.getReceivedAt().toString());
        dataMap.put("lastUpdated", LocalDateTime.now().toString());
        
        // Redis Hashì— ì €ì¥ (TTL: 1ì‹œê°„)
        redisTemplate.opsForHash().putAll(key, dataMap);
        redisTemplate.expire(key, Duration.ofHours(1));
        
        // ìµœì‹  ì—…ë°ì´íŠ¸ ì‹œê°„ ê¸°ë¡
        redisTemplate.opsForValue().set(LATEST_UPDATE_KEY, 
            LocalDateTime.now().toString(), Duration.ofHours(1));
    }
    
    /**
     * ì²­í¬ë¥¼ ì••ì¶•í•˜ì—¬ Redisì— ì €ì¥
     * @param stockId ì¢…ëª© ID
     * @param chunk ì €ì¥í•  ì²­í¬
     */
//    private void saveBatchToRedis(Integer stockId, TickChunk chunk) {
//        try {
//            if (chunk.isEmpty()) {
//                return;
//            }
//
//            // ì••ì¶•ëœ ë°ì´í„° ìƒì„±
//            byte[] compressed = chunk.toCompressedBlob(ZSTD_LEVEL);
//
//            // Redis í‚¤ ìƒì„± (stockId + timestamp)
//            String key = String.format("%s%d:%d", BATCH_KEY_PREFIX, stockId, System.currentTimeMillis());
//
//            // ì••ì¶•ëœ ë°”ì´ë„ˆë¦¬ ë°ì´í„° ì €ì¥ (TTL: 24ì‹œê°„)
//            binaryRedisTemplate.opsForValue().set(key, compressed, Duration.ofHours(24));
//
//            // ë©”íƒ€ë°ì´í„° ì €ì¥
//            String metaKey = META_KEY_PREFIX + stockId;
//            String metaValue = String.format("count=%d,size=%d,ratio=%.2f%%,key=%s",
//                chunk.count(), compressed.length,
//                chunk.getCompressionRatio(compressed.length), key);
//
//            redisTemplate.opsForHash().put(metaKey, key, metaValue);
//            redisTemplate.expire(metaKey, Duration.ofHours(24));
//
//            // í†µê³„ ë¡œê·¸
//            String stockCode = stockIdMapper.getStockCode(stockId);
//            log.info("ğŸ“¦ Compressed batch saved: {} ({}) - {} ticks, {} bytes, {:.1f}% ratio",
//                stockCode, stockId, chunk.count(), compressed.length,
//                chunk.getCompressionRatio(compressed.length));
//
//        } catch (Exception e) {
//            log.error("Failed to save compressed batch: {}", e.getMessage(), e);
//        }
//    }
    private void saveBatchToRedis(Integer stockId, TickChunk chunk) {
        try {
            if (chunk.isEmpty()) return;

            // 1) ì••ì¶• + ê¸°ë³¸ ë©”íƒ€ ê³„ì‚°
            byte[] compressed = chunk.toCompressedBlob(ZSTD_LEVEL);
            int count = chunk.count();
            int rawBytes = count * 16;

            // 2) (ê¸°ì¡´) ë ˆê±°ì‹œ í‚¤ì—ë„ ì €ì¥
            String legacyKey = String.format("%s%d:%d", BATCH_KEY_PREFIX, stockId, System.currentTimeMillis());
            binaryRedisTemplate.opsForValue().set(legacyKey, compressed, Duration.ofHours(24));

            // 3) (ê¸°ì¡´) ì¢…ëª©ë³„ ë©”íƒ€ í•´ì‹œ ì—…ë°ì´íŠ¸
            String metaKeyPerStock = META_KEY_PREFIX + stockId;
            String metaValue = String.format("count=%d,size=%d,ratio=%.2f%%,key=%s",
                    count, compressed.length, chunk.getCompressionRatio(compressed.length), legacyKey);
            redisTemplate.opsForHash().put(metaKeyPerStock, legacyKey, metaValue);
            redisTemplate.expire(metaKeyPerStock, Duration.ofHours(24));

            // ---------------------------
            // [NEW] per-chunk ì €ì¥ + ì¸ë±ìŠ¤
            // ---------------------------
            // 4) ì²­í¬ ID
            String chunkId = java.util.UUID.randomUUID().toString();

            // 5) blob ì €ì¥ (ticks:chunk:{id}:blob)
            String chunkBlobKey = "ticks:chunk:" + chunkId + ":blob";
            binaryRedisTemplate.opsForValue().set(chunkBlobKey, compressed, Duration.ofDays(1));

            // 6) meta ì €ì¥ (ticks:chunk:{id}:meta)
            String chunkMetaKey = "ticks:chunk:" + chunkId + ":meta";
            Map<String, String> meta = new HashMap<>();
            meta.put("count", String.valueOf(count));
            meta.put("rawBytes", String.valueOf(rawBytes));                         // = count * 16
            meta.put("baseDate", java.time.LocalDate.now(java.time.ZoneId.of("Asia/Seoul")).toString()); // KST
            meta.put("zstdLevel", String.valueOf(ZSTD_LEVEL));
            meta.put("ver", "1");
            meta.put("endian", "LE");
            meta.put("stockId", String.valueOf(stockId));
            meta.put("createdAt", java.time.LocalDateTime.now().toString());
            redisTemplate.opsForHash().putAll(chunkMetaKey, meta);
            redisTemplate.expire(chunkMetaKey, Duration.ofDays(1));

            // 7) ì¸ë±ìŠ¤(ZSET)
            long createdAt = System.currentTimeMillis();

            // ì¡°íšŒ/ë¦¬ìŠ¤íŠ¸ ì¸ë±ìŠ¤ëŠ” ìƒì„±ì‹œê° ê·¸ëŒ€ë¡œ
            redisTemplate.opsForZSet().add("ticks:chunks", chunkId, createdAt);
            redisTemplate.opsForZSet().add("ticks:chunks:byStock:" + stockId, chunkId, createdAt);

            // DB ì ì¬ ëŒ€ê¸°ì—´ì€ +10ì´ˆë¡œ ìŠ¤ì¼€ì¤„
            redisTemplate.opsForZSet().add("ticks:ingest:pending", chunkId, createdAt + 10_000);


            // 8) ë¡œê·¸
            String stockCode = stockIdMapper.getStockCode(stockId);
            double ratio = chunk.getCompressionRatio(compressed.length);
            log.info("ğŸ“¦ Compressed batch saved: {} ({}) - ticks={}, blob={}B, ratio={}%, chunkId={}",
                    stockCode, stockId, count, compressed.length, String.format("%.1f", ratio), chunkId);

        } catch (Exception e) {
            log.error("Failed to save compressed batch: {}", e.getMessage(), e);
        }
    }


    /**
     * Redisì—ì„œ íŠ¹ì • ì¢…ëª©ì˜ ìµœì‹  í‹± ë°ì´í„° ì¡°íšŒ
     * 
     * @param stockCode ì¢…ëª© ì½”ë“œ
     * @return TickData ë˜ëŠ” null
     */
    public TickData getTickData(String stockCode) {
        try {
            String key = REALTIME_KEY_PREFIX + stockCode;
            Map<Object, Object> dataMap = redisTemplate.opsForHash().entries(key);
            
            if (dataMap.isEmpty()) {
                return null;
            }
            
            // Mapì„ TickDataë¡œ ë³€í™˜
            return convertMapToTickData(dataMap);
            
        } catch (Exception e) {
            System.err.println("Failed to get tick data from Redis: " + e.getMessage());
            return null;
        }
    }
    
    /**
     * Redisì—ì„œ ëª¨ë“  í‹± ë°ì´í„° ì¡°íšŒ
     * 
     * @return ì¢…ëª©ì½”ë“œë³„ í‹± ë°ì´í„° Map
     */
    public Map<String, TickData> getAllTickData() {
        try {
            Set<String> keys = redisTemplate.keys(REALTIME_KEY_PREFIX + "*");
            Map<String, TickData> result = new HashMap<>();
            
            for (String key : keys) {
                String stockCode = key.replace(REALTIME_KEY_PREFIX, "");
                Map<Object, Object> dataMap = redisTemplate.opsForHash().entries(key);
                
                if (!dataMap.isEmpty()) {
                    TickData data = convertMapToTickData(dataMap);
                    if (data != null) {
                        result.put(stockCode, data);
                    }
                }
            }
            
            return result;
            
        } catch (Exception e) {
            System.err.println("Failed to get all tick data from Redis: " + e.getMessage());
            return new HashMap<>();
        }
    }
    
    /**
     * Redisì—ì„œ íŠ¹ì • ì¢…ëª© ë°ì´í„° ì‚­ì œ
     * 
     * @param stockCode ì¢…ëª© ì½”ë“œ
     */
    public void deleteRealtimeData(String stockCode) {
        try {
            String key = REALTIME_KEY_PREFIX + stockCode;
            redisTemplate.delete(key);
            System.out.println("Deleted realtime data from Redis: " + stockCode);
        } catch (Exception e) {
            System.err.println("Failed to delete realtime data from Redis: " + e.getMessage());
        }
    }
    
    /**
     * ëª¨ë“  ì‹¤ì‹œê°„ ë°ì´í„° ì‚­ì œ
     */
    public void clearAllRealtimeData() {
        try {
            Set<String> keys = redisTemplate.keys(REALTIME_KEY_PREFIX + "*");
            if (!keys.isEmpty()) {
                redisTemplate.delete(keys);
                System.out.println("Cleared all realtime data from Redis");
            }
        } catch (Exception e) {
            System.err.println("Failed to clear realtime data from Redis: " + e.getMessage());
        }
    }
    
    /**
     * Redis Hash Mapì„ TickData ê°ì²´ë¡œ ë³€í™˜
     */
    private TickData convertMapToTickData(Map<Object, Object> dataMap) {
        try {
            return TickData.builder()
                    .code((String) dataMap.get("code"))
                    .date((String) dataMap.get("date"))
                    .closePrice(Integer.parseInt((String) dataMap.get("closePrice")))
                    .openPrice(Integer.parseInt((String) dataMap.get("openPrice")))
                    .highPrice(Integer.parseInt((String) dataMap.get("highPrice")))
                    .lowPrice(Integer.parseInt((String) dataMap.get("lowPrice")))
                    .volume(Integer.parseInt((String) dataMap.get("volume")))
                    .receivedAt(LocalDateTime.parse((String) dataMap.get("receivedAt")))
                    .build();
        } catch (Exception e) {
            System.err.println("Failed to convert map to TickData: " + e.getMessage());
            return null;
        }
    }
    
    /**
     * íŠ¹ì • ì¢…ëª©ì˜ ìµœì‹  ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ (ë§¤ë§¤ ì²˜ë¦¬ìš©)
     * 
     * @param stockCode ì¢…ëª© ì½”ë“œ (ì˜ˆ: "005930")
     * @return ìµœì‹  ì¢…ê°€, Redisì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ null
     */
    public Integer getLatestPrice(String stockCode) {
        try {
            String key = REALTIME_KEY_PREFIX + stockCode; // "realtime:stock:005930"
            String priceStr = (String) redisTemplate.opsForHash().get(key, "closePrice");
            
            if (priceStr != null) {
                Integer price = Integer.parseInt(priceStr);
                log.debug("Redisì—ì„œ ì¢…ëª© {} ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ: {}ì›", stockCode, price);
                return price;
            } else {
                log.warn("Redisì— ì¢…ëª© {} ì‹¤ì‹œê°„ ê°€ê²© ë°ì´í„° ì—†ìŒ", stockCode);
                return null;
            }
        } catch (Exception e) {
            log.error("ì¢…ëª© {} ì‹¤ì‹œê°„ ê°€ê²© ì¡°íšŒ ì‹¤íŒ¨", stockCode, e);
            return null;
        }
    }

    /**
     * Redis ì—°ê²° ìƒíƒœ í™•ì¸
     * 
     * @return true if connected
     */
    public boolean isRedisConnected() {
        try {
            redisTemplate.opsForValue().set("health:check", "ok", Duration.ofSeconds(1));
            String result = redisTemplate.opsForValue().get("health:check");
            return "ok".equals(result);
        } catch (Exception e) {
            return false;
        }
    }
    
    /**
     * ìŠ¤ì¼€ì¤„ëŸ¬: ë¯¸ì™„ì„± ì²­í¬ë“¤ì„ ì •ê¸°ì ìœ¼ë¡œ Redisì— ì €ì¥
     * 1ë¶„ë§ˆë‹¤ ì‹¤í–‰í•˜ì—¬ ë©”ëª¨ë¦¬ì— ë‚¨ì•„ìˆëŠ” ì²­í¬ë“¤ ì €ì¥
     */
    @Scheduled(fixedRate = 60000) // 1ë¶„ë§ˆë‹¤
    public void flushPendingChunks() {
        try {
            int flushedCount = 0;
            
            for (Map.Entry<Integer, TickChunk> entry : stockChunks.entrySet()) {
                Integer stockId = entry.getKey();
                TickChunk chunk = entry.getValue();
                
                if (!chunk.isEmpty()) {
                    saveBatchToRedis(stockId, chunk);
                    chunk.reset();  // ì²­í¬ ì¬ì‚¬ìš©ì„ ìœ„í•´ ë¦¬ì…‹
                    flushedCount++;
                }
            }
            
            if (flushedCount > 0) {
                log.info("ğŸ”„ Scheduled flush completed: {} chunks saved", flushedCount);
            }
            
        } catch (Exception e) {
            log.error("Failed to flush pending chunks: {}", e.getMessage(), e);
        }
    }
    
    /**
     * ì••ì¶• ë°°ì¹˜ ì €ì¥ í†µê³„ ì •ë³´ ì¡°íšŒ
     * @return í†µê³„ ë§µ
     */
    public Map<String, Object> getBatchStatistics() {
        Map<String, Object> stats = new HashMap<>();
        
        try {
            int totalChunks = stockChunks.size();
            int totalTicks = stockChunks.values().stream()
                .mapToInt(TickChunk::count)
                .sum();
                
            stats.put("activeChunks", totalChunks);
            stats.put("pendingTicks", totalTicks);
            stats.put("chunkSize", CHUNK_SIZE);
            stats.put("compressionLevel", ZSTD_LEVEL);
            stats.put("lastUpdate", getLastUpdateTime());
            
        } catch (Exception e) {
            log.error("Failed to get batch statistics: {}", e.getMessage());
        }
        
        return stats;
    }
    
    /**
     * íŠ¹ì • ì¢…ëª©ì˜ ì••ì¶• ë°°ì¹˜ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
     * @param stockCode ì¢…ëª©ì½”ë“œ
     * @return ë©”íƒ€ë°ì´í„° ë§µ
     */
    public Map<Object, Object> getBatchMetadata(String stockCode) {
        try {
            Integer stockId = stockIdMapper.getStockId(stockCode);
            if (stockId == null) {
                return new HashMap<>();
            }
            
            String metaKey = META_KEY_PREFIX + stockId;
            return redisTemplate.opsForHash().entries(metaKey);
            
        } catch (Exception e) {
            log.error("Failed to get batch metadata for {}: {}", stockCode, e.getMessage());
            return new HashMap<>();
        }
    }
    
    /**
     * ìµœê·¼ ì—…ë°ì´íŠ¸ ì‹œê°„ ì¡°íšŒ
     */
    public String getLastUpdateTime() {
        try {
            return redisTemplate.opsForValue().get(LATEST_UPDATE_KEY);
        } catch (Exception e) {
            return null;
        }
    }
    
    /**
     * ë©”ëª¨ë¦¬ ì •ë¦¬: ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì²­í¬ ì œê±°
     */
    public void cleanupMemory() {
        try {
            int before = stockChunks.size();
            stockChunks.entrySet().removeIf(entry -> entry.getValue().isEmpty()); // ë¹„ì–´ìˆëŠ” ì²­í¬ ì œê±°
            int removedCount = before - stockChunks.size();
            
            if (removedCount > 0) {
                log.info("ğŸ§¹ Memory cleanup completed: {} empty chunks removed", removedCount);
            }
            
        } catch (Exception e) {
            log.error("Failed to cleanup memory: {}", e.getMessage(), e);
        }
    }

    // [NEW] ìµœì‹  ì²­í¬ ID ëª©ë¡
    public java.util.List<String> latestChunkIds(int limit) {
        var ids = redisTemplate.opsForZSet().reverseRange(CHUNKS_ZSET_ALL, 0, limit - 1);
        return ids == null ? java.util.List.of() : ids.stream().toList();
    }

    // [NEW] ì¢…ëª©ë³„ ìµœì‹  ì²­í¬ ID ëª©ë¡
    public java.util.List<String> latestChunkIdsByStock(int stockId, int limit) {
        var key = String.format(CHUNKS_ZSET_BY_STOCK, stockId);
        var ids = redisTemplate.opsForZSet().reverseRange(key, 0, limit - 1);
        return ids == null ? java.util.List.of() : ids.stream().toList();
    }


}