import pandas as pd
import psycopg2
from psycopg2.extras import execute_batch
import os
import re
from datetime import datetime

# DB ì—°ê²° ì •ë³´
DB_CONFIG = {
    'host': 'i13d203.p.ssafy.io',
    'port': 5432,
    'database': 'stock_db', 
    'user': 'ssafyuser',
    'password': 'ssafypw!!'
}

# ì™„ì „í•œ ë§¤í•‘ í…Œì´ë¸” (CSV ì½”ë“œ -> DB ì½”ë“œ -> stock_info_id)
CSV_TO_DB_MAPPING = {
    '005930': '5930',   # ì‚¼ì„±ì „ì -> 1
    '000270': '270',    # ê¸°ì•„ -> 2  
    '003670': '3670',   # í¬ìŠ¤ì½”í“¨ì²˜ì—  -> 3
    '005380': '5380',   # í˜„ëŒ€ì°¨ -> 4
    '005490': '5490',   # í¬ìŠ¤ì½”í™€ë”©ìŠ¤ -> 5
    '006400': '6400',   # ì‚¼ì„±SDI -> 6
    '012330': '12330',  # í˜„ëŒ€ëª¨ë¹„ìŠ¤ -> 7
    '015760': '15760',  # í•œêµ­ì „ë ¥ -> 8
    '017670': '17670',  # SKí…”ë ˆì½¤ -> 9
    '017810': '17810',  # í’€ë¬´ì› -> 10
    '028260': '28260',  # ì‚¼ì„±ë¬¼ì‚° -> 11
    '032640': '32640',  # LGìœ í”ŒëŸ¬ìŠ¤ -> 12
    '032830': '32830',  # ì‚¼ì„±ìƒëª… -> 13
    '033780': '33780',  # KT&G -> 14
    '034020': '34020',  # ë‘ì‚°ì—ë„ˆë¹Œë¦¬í‹° -> 15
    '035420': '35420',  # ë„¤ì´ë²„ -> 16
    '036460': '36460',  # í•œêµ­ê°€ìŠ¤ê³µì‚¬ -> 17
    '058470': '58470',  # ë¦¬ë…¸ê³µì—… -> 18
    '005940': '5940',   # NHíˆ¬ìì¦ê¶Œ -> 19
    '066570': '66570',  # LGì „ì -> 20
    '066970': '66970',  # ì—˜ì•¤ì—í”„ -> 21
    '068270': '68270',  # ì…€íŠ¸ë¦¬ì˜¨ -> 22
    '086790': '86790',  # í•˜ë‚˜ê¸ˆìœµì§€ì£¼ -> 23
    '088980': '88980',  # ë§¥ì¿¼ë¦¬ì¸í”„ë¼ -> 24
    '090430': '90430',  # ì•„ëª¨ë ˆí¼ì‹œí”½ -> 25
    '097950': '97950',  # CJì œì¼ì œë‹¹ -> 26
    '105560': '105560', # KBê¸ˆìœµ -> 27
    '196170': '196170', # ì•Œí…Œì˜¤ì   -> 28
    '207940': '207940', # ì‚¼ì„±ë°”ì´ì˜¤ë¡œì§ìŠ¤ -> 29
    '247540': '247540', # ì—ì½”í”„ë¡œë¹„ì—  -> 30
    '252670': '252670', # ì½”ìŠ¤í”¼200TR -> 31
    '263750': '263750', # í„ì–´ë¹„ìŠ¤ -> 32
    '267260': '267260', # HDí˜„ëŒ€ì¼ë ‰íŠ¸ë¦­ -> 33
    '293490': '293490', # ì¹´ì¹´ì˜¤ê²Œì„ì¦ˆ -> 34
    '316140': '316140', # ìš°ë¦¬ê¸ˆìœµì§€ì£¼ -> 35
    '373220': '373220', # LGì—ë„ˆì§€ì†”ë£¨ì…˜ -> 36
    '000660': '660',    # SKí•˜ì´ë‹‰ìŠ¤ -> 37
    '051910': '51910',  # LGí™”í•™ -> 38
    '055550': '55550',  # ì‹ í•œì§€ì£¼ -> 39
    '030200': '30200'   # KT -> 40
}

DB_STOCK_INFO = {
    '5930': 1, '270': 2, '3670': 3, '5380': 4, '5490': 5,
    '6400': 6, '12330': 7, '15760': 8, '17670': 9, '17810': 10,
    '28260': 11, '32640': 12, '32830': 13, '33780': 14, '34020': 15,
    '35420': 16, '36460': 17, '58470': 18, '5940': 19, '66570': 20,
    '66970': 21, '68270': 22, '86790': 23, '88980': 24, '90430': 25,
    '97950': 26, '105560': 27, '196170': 28, '207940': 29, '247540': 30,
    '252670': 31, '263750': 32, '267260': 33, '293490': 34, '316140': 35,
    '373220': 36, '660': 37, '51910': 38, '55550': 39, '30200': 40
}

def process_all_csv_files():
    """ëª¨ë“  CSV íŒŒì¼ ì²˜ë¦¬"""
    csv_dir = r"C:\Users\SSAFY\Desktop\project\ì°¨íŠ¸ ë°ì´í„°\ë¶„ë´‰ ìµœì‹ í™”(25. 8. 14.)"
    csv_files = [f for f in os.listdir(csv_dir) if f.endswith('.csv')]
    
    print(f"ğŸš€ ì „ì²´ {len(csv_files)}ê°œ CSV íŒŒì¼ ëŒ€ëŸ‰ ì‚½ì… ì‹œì‘!")
    print(f"ğŸ“… ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    all_data = []
    processed_files = 0
    skipped_files = 0
    
    for csv_file in csv_files:
        try:
            # íŒŒì¼ëª…ì—ì„œ ì¢…ëª©ì½”ë“œ ì¶”ì¶œ
            match = re.search(r'\((\d{6})\)', csv_file)
            if not match:
                print(f"âš ï¸  ì½”ë“œ ì¶”ì¶œ ì‹¤íŒ¨: {csv_file}")
                skipped_files += 1
                continue
                
            csv_code = match.group(1)
            
            # ë§¤í•‘ í™•ì¸
            if csv_code not in CSV_TO_DB_MAPPING:
                print(f"âš ï¸  ë§¤í•‘ ì—†ìŒ: {csv_file} ({csv_code})")
                skipped_files += 1
                continue
                
            db_code = CSV_TO_DB_MAPPING[csv_code]
            if db_code not in DB_STOCK_INFO:
                print(f"âš ï¸  DBì— ì—†ìŒ: {csv_file} ({db_code})")
                skipped_files += 1
                continue
                
            stock_info_id = DB_STOCK_INFO[db_code]
            
            # CSV íŒŒì¼ ì²˜ë¦¬
            filepath = os.path.join(csv_dir, csv_file)
            df = pd.read_csv(filepath, encoding='utf-8-sig')
            
            # ë°ì´í„° ë³€í™˜
            for _, row in df.iterrows():
                ts = pd.to_datetime(row['datetime']).strftime('%Y-%m-%d %H:%M:%S+09')
                all_data.append((
                    stock_info_id,
                    ts,
                    int(row['open']),
                    int(row['high']), 
                    int(row['low']),
                    int(row['close']),
                    int(row['volume'])
                ))
            
            processed_files += 1
            print(f"âœ… {processed_files:2d}/40 {csv_file[:25]}... -> ID:{stock_info_id} ({len(df):,}ê±´)")
            
            # ë©”ëª¨ë¦¬ ê´€ë¦¬ (50ë§Œê±´ë§ˆë‹¤ DB ì‚½ì…)
            if len(all_data) >= 500000:
                print(f"ğŸ’¾ ì¤‘ê°„ ì‚½ì…: {len(all_data):,}ê±´")
                bulk_insert_to_db(all_data)
                all_data = []
            
        except Exception as e:
            print(f"âŒ {csv_file} ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            skipped_files += 1
            continue
    
    # ë‚¨ì€ ë°ì´í„° ì‚½ì…
    if all_data:
        print(f"ğŸ’¾ ìµœì¢… ì‚½ì…: {len(all_data):,}ê±´")
        bulk_insert_to_db(all_data)
    
    print(f"\nğŸ‰ ì²˜ë¦¬ ì™„ë£Œ!")
    print(f"âœ… ì„±ê³µ: {processed_files}/40ê°œ íŒŒì¼")
    print(f"âŒ ì‹¤íŒ¨: {skipped_files}/40ê°œ íŒŒì¼")
    print(f"ğŸ“… ì¢…ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    return processed_files, skipped_files

def bulk_insert_to_db(data_rows):
    """ëŒ€ëŸ‰ ë°ì´í„° ì‚½ì…"""
    if not data_rows:
        return
        
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        # ë°°ì¹˜ ì‚½ì… (ì¶©ëŒì‹œ ì—…ë°ì´íŠ¸) - execute_batch í˜¸í™˜ í˜•ì‹
        insert_query = """
            INSERT INTO ticks (stock_info_id, ts, open_price, high_price, low_price, close_price, volume) 
            VALUES (%s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (stock_info_id, ts) DO UPDATE SET
                open_price = EXCLUDED.open_price,
                high_price = EXCLUDED.high_price,
                low_price = EXCLUDED.low_price,
                close_price = EXCLUDED.close_price,
                volume = EXCLUDED.volume
        """
        
        # 5000ê°œì”© ë°°ì¹˜ ì²˜ë¦¬
        batch_size = 5000
        total_inserted = 0
        
        for i in range(0, len(data_rows), batch_size):
            batch = data_rows[i:i + batch_size]
            execute_batch(cursor, insert_query, batch, page_size=batch_size)
            total_inserted += len(batch)
            
            if total_inserted % 50000 == 0:
                print(f"   ì§„í–‰: {total_inserted:,}ê±´ ì‚½ì… ì™„ë£Œ")
        
        conn.commit()
        cursor.close()
        conn.close()
        
        print(f"   âœ… ì´ {total_inserted:,}ê±´ ì‚½ì… ì™„ë£Œ")
        
    except Exception as e:
        print(f"   âŒ DB ì‚½ì… ì‹¤íŒ¨: {e}")
        if 'conn' in locals():
            conn.rollback()

def check_final_results():
    """ìµœì¢… ê²°ê³¼ í™•ì¸"""
    try:
        conn = psycopg2.connect(**DB_CONFIG)
        cursor = conn.cursor()
        
        # ì „ì²´ ë°ì´í„° ìˆ˜
        cursor.execute("SELECT COUNT(*) FROM ticks;")
        total_count = cursor.fetchone()[0]
        
        # ì¢…ëª©ë³„ ë°ì´í„° ìˆ˜
        cursor.execute("""
            SELECT stock_info_id, COUNT(*) as count
            FROM ticks 
            GROUP BY stock_info_id 
            ORDER BY stock_info_id
        """)
        stock_counts = cursor.fetchall()
        
        cursor.close()
        conn.close()
        
        print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼:")
        print(f"ì „ì²´ ë°ì´í„°: {total_count:,}ê±´")
        print(f"ì¢…ëª©ë³„ í˜„í™©:")
        for stock_id, count in stock_counts:
            print(f"  stock_info_id {stock_id:2d}: {count:,}ê±´")
            
    except Exception as e:
        print(f"âŒ ê²°ê³¼ í™•ì¸ ì‹¤íŒ¨: {e}")

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸš€ LAGO í”„ë¡œì íŠ¸ - ì „ì²´ CSV ë°ì´í„° ëŒ€ëŸ‰ ì‚½ì…")
    print("=" * 60)
    
    # í™•ì¸
    response = input("40ê°œ íŒŒì¼ ì „ì²´ë¥¼ ì‚½ì…í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ").lower()
    if response != 'y':
        print("âŒ ì‚¬ìš©ìê°€ ì·¨ì†Œí–ˆìŠµë‹ˆë‹¤.")
        exit()
    
    # ì‹¤í–‰
    success_count, fail_count = process_all_csv_files()
    
    # ê²°ê³¼ í™•ì¸
    if success_count > 0:
        check_final_results()
    
    print("\nğŸ‰ ëª¨ë“  ì‘ì—…ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")